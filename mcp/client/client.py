# mcp/math_client.py
import asyncio
import os

from dotenv import load_dotenv
from langchain_core.tools import Tool
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_openai import ChatOpenAI

from langchain.agents import create_agent

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½® MCP æœåŠ¡å™¨åœ°å€
# è¯·ç¡®ä¿ server.py å·²ç»è¿è¡Œ
MCP_SERVER_URL = "http://127.0.0.1:8000/mcp"


async def main():
    # --- æ­¥éª¤ 1: åˆå§‹åŒ– MCP å®¢æˆ·ç«¯ ---
    # MultiServerMCPClient æ”¯æŒè¿æ¥å¤šä¸ª MCP æœåŠ¡å™¨
    mcp_client = MultiServerMCPClient(
        {
            "MATH Local": {  # æœåŠ¡å™¨åˆ«å
                "transport": "stdio",  # ä¼ è¾“åè®®
                "command": "python",
                "args": ["mcp/server/server_stdio.py"],
            },
            "MATH Remote": {  # æœåŠ¡å™¨åˆ«å
                "transport": "streamable-http",  # ä¼ è¾“åè®®
                "url": MCP_SERVER_URL,
                # å¦‚æœæœåŠ¡ç«¯éœ€è¦è®¤è¯ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ  headers
                # "headers": {"Authorization": "Bearer your-token"}
            },
        }
    )
    # --- æ­¥éª¤ 2: åŠ è½½ MCP å·¥å…· ---
    # è¿™ä¼šè‡ªåŠ¨ä»è¿œç¨‹æœåŠ¡å™¨è·å–å·¥å…·åˆ—è¡¨ï¼Œå¹¶è½¬æ¢ä¸º LangChain Tool å¯¹è±¡
    print("ğŸš€ æ­£åœ¨åŠ è½½ MCP å·¥å…·...")
    mcp_tools = await mcp_client.get_tools()

    for tool in mcp_tools:
        print(f"âœ… åŠ è½½å·¥å…·: {tool.name}")

    # --- æ­¥éª¤ 3: åˆå§‹åŒ–å¤§æ¨¡å‹ ---
    model = ChatOpenAI(
        model=os.getenv("MODEL_NAME", "gpt-4o-mini"),
        api_key=os.getenv("MODEL_API_KEY"),
        base_url=os.getenv("PROXY_BASE_URL", "https://free.v36.cm/v1"),
        temperature=0.8,
    )

    # --- æ­¥éª¤ 4: åˆ›å»º Agent ---
    # å°† MCP å·¥å…·æ³¨å…¥åˆ° Agent ä¸­
    agent = create_agent(
        model=model,
        tools=mcp_tools,
        # å¯ä»¥è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ï¼Œå¼•å¯¼ Agent ä¼˜å…ˆä½¿ç”¨å·¥å…·
        # state_modifier="You are a helpful assistant that can use tools."
    )

    # --- æ­¥éª¤ 5: è°ƒç”¨ Agent ---
    # è¿™é‡Œæ¼”ç¤ºä¸€ä¸ªåŒ…å«è®¡ç®—å’Œèµ„æºè¯»å–çš„å¤æ‚é—®é¢˜
    print("\nğŸ¤– å¼€å§‹å¯¹è¯...")
    async for chunk in agent.astream(
        {
            "messages": [
                ("human", "å…ˆè¯»å–é»˜è®¤é—®å€™èµ„æºï¼Œç„¶åè®¡ç®— 5 åŠ  3 çš„å’Œ ä¹˜ä»¥ 8 çš„ç»“æœ"),
            ],
        }
    ):
        # å®æ—¶æ‰“å° Agent çš„æ€è€ƒå’Œæœ€ç»ˆç»“æœ
        # content = chunk["model"]["messages"][-1].content
        # --- å¼€å§‹å…¼å®¹æ€§å¤„ç† ---
        content = None

        # æƒ…å†µ 1: æ•°æ®åœ¨ chunk["model"]["messages"] é‡Œ (ä½ ä¹‹å‰é‡åˆ°çš„ç»“æ„)
        if "model" in chunk:
            messages = chunk["model"].get("messages", [])
            if messages:
                content = messages[-1].content
        if content:
            print(content, end="", flush=True)
    # finally:
    #     # --- æ­¥éª¤ 6: æ¸…ç†èµ„æº ---
    #     # await mcp_client.aclose()
    #     print("-" * 50)
    #     print(dir(mcp_client))


if __name__ == "__main__":
    asyncio.run(main())
